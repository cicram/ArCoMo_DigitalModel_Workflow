import csv
import math
import numpy as np
import open3d as o3d
import os
from PIL import Image, ImageChops
from sklearn.neighbors import NearestNeighbors
import ast

from workflow_stent_calc_center_line_registration import center_line_registration
from workflow_stent_calc_center_line_smooting_gui import PointCloudSmoothingVisualizer
from workflow_stent_calc_center_line_registration_point_selection_GUI import PointCloudRegistrationPointSelectionVisualizer
from workflow_stent_calc_visual_pointcloud_editing_VTK_point import point_cloud_visual_editing

def get_rotation_matrix_ICP(oct_lumen_contours, z_distance):
    previous_contour = None
    rotations = []
    total_rotations = []
    rotation_total = 0
    rotation = 0
    z_previous = 0
    flag = True
    for current_contour in oct_lumen_contours:
        z_current = current_contour[0][2]
        while True:
            z_diff = z_current - z_previous
            current_contour = [(x[0], x[1]) for x in current_contour]
            
            if (z_diff) < (z_distance + 0.01):
                if previous_contour is not None:
                    flag = False
                    # Perform ICP alignment.
                    rotation = icp_alignment(current_contour, previous_contour)
                    previous_contour = current_contour
                    rotation_total += rotation
                    rotations.append(rotation)
                    total_rotations.append(rotation_total)
                    z_previous = z_current
                    break
                else:
                    previous_contour = current_contour
                    rotation = 0
                    rotation_total += rotation
                    rotations.append(rotation)
                    total_rotations.append(rotation_total)
                    break
            else:
                z_previous += z_distance
                rotation = 0
                rotation_total += rotation
                rotations.append(rotation)
                total_rotations.append(rotation_total)
        
    return np.array(total_rotations)

# Estimate rotation and translations
def point_based_matching(point_pairs):
    """
    This function is based on the paper "Robot Pose Estimation in Unknown Environments by Matching 2D Range Scans"
    by F. Lu and E. Milios.

    :param point_pairs: the matched point pairs [((x1, y1), (x1', y1')), ..., ((xi, yi), (xi', yi')), ...]
    :return: the rotation angle and the 2D translation (x, y) to be applied for matching the given pairs of points
    """
    x_mean = 0
    y_mean = 0
    xp_mean = 0
    yp_mean = 0
    n = len(point_pairs)

    if n == 0:
        return None, None, None

    for pair in point_pairs:

        (x, y), (xp, yp) = pair

        x_mean += x
        y_mean += y
        xp_mean += xp
        yp_mean += yp

    x_mean /= n
    y_mean /= n
    xp_mean /= n
    yp_mean /= n

    s_x_xp = 0
    s_y_yp = 0
    s_x_yp = 0
    s_y_xp = 0
    for pair in point_pairs:

        (x, y), (xp, yp) = pair

        s_x_xp += (x - x_mean)*(xp - xp_mean)
        s_y_yp += (y - y_mean)*(yp - yp_mean)
        s_x_yp += (x - x_mean)*(yp - yp_mean)
        s_y_xp += (y - y_mean)*(xp - xp_mean)

    rot_angle = math.atan2(s_x_yp - s_y_xp, s_x_xp + s_y_yp)
    translation_x = xp_mean - (x_mean*math.cos(rot_angle) - y_mean*math.sin(rot_angle))
    translation_y = yp_mean - (x_mean*math.sin(rot_angle) + y_mean*math.cos(rot_angle))

    return rot_angle, translation_x, translation_y


def icp_alignment(points, reference_points, max_iterations=100, distance_threshold=100, convergence_translation_threshold=1e-3,
        convergence_rotation_threshold=1e-4, point_pairs_threshold=10, verbose=False):
    """
    An implementation of the Iterative Closest Point algorithm that matches a set of M 2D points to another set
    of N 2D (reference) points.

    :param reference_points: the reference point set as a numpy array (N x 2)
    :param points: the point that should be aligned to the reference_points set as a numpy array (M x 2)
    :param max_iterations: the maximum number of iteration to be executed
    :param distance_threshold: the distance threshold between two points in order to be considered as a pair
    :param convergence_translation_threshold: the threshold for the translation parameters (x and y) for the
                                            transformation to be considered converged
    :param convergence_rotation_threshold: the threshold for the rotation angle (in rad) for the transformation
                                            to be considered converged
    :param point_pairs_threshold: the minimum number of point pairs the should exist
    :param verbose: whether to print informative messages about the process (default: False)
    :return: the transformation history as a list of numpy arrays containing the rotation (R) and translation (T)
            transformation in each iteration in the format [R | T] and the aligned points as a numpy array M x 2
    """
    max_rotation_flag = False
    all_points = []
    transformation_history = []
    iteration_array = []
    translation_x_mm = []
    translation_y_mm = []
    distance_between_points = []
    total_rotation_degrees = 0
    total_trans_x = 0
    total_trans_y = 0
    rotation_degrees = []
    final_rotation = np.array([[ 1, 0], [ 0,  1]])
    source_points_orig = np.copy(points)
    nbrs = NearestNeighbors(n_neighbors=1, algorithm='kd_tree').fit(reference_points)
    
    for iter_num in range(max_iterations):
        if verbose:
            print('------ iteration', iter_num, '------')

        closest_point_pairs = []  # list of point correspondences for closest point rule

        distances, indices = nbrs.kneighbors(points)
        for nn_index in range(len(distances)):
            if distances[nn_index][0] < distance_threshold:
                closest_point_pairs.append((points[nn_index], reference_points[indices[nn_index][0]]))

        # if only few point pairs, stop process
        if verbose:
            print('number of pairs found:', len(closest_point_pairs))
        if len(closest_point_pairs) < point_pairs_threshold:
            if verbose:
                print('No better solution can be found (very few point pairs)!')
            break

        # compute translation and rotation using point correspondences
        closest_rot_angle, closest_translation_x, closest_translation_y = point_based_matching(closest_point_pairs)
        if closest_rot_angle is not None:
            if verbose:
                print('Rotation:', math.degrees(closest_rot_angle), 'degrees')
                print('Translation:', closest_translation_x, closest_translation_y)
                    
        if closest_rot_angle is None or closest_translation_x is None or closest_translation_y is None:
            print("No better solution can be found!")
            if verbose:
                print('No better solution can be found!')
            break
        
        # transform 'points' (using the calculated rotation and translation)
        c, s = math.cos(closest_rot_angle), math.sin(closest_rot_angle)
        rot = np.array([[c, -s],
                        [s, c]])
        aligned_points = np.dot(points, rot.T)
        aligned_points[:, 0] += closest_translation_x 
        aligned_points[:, 1] += closest_translation_y

        # update 'points' for the next iteration
        points = aligned_points
        all_points.append(np.copy(points))
        # update transformation history
        transformation_history.append(np.hstack((rot, np.array([[closest_translation_x], [closest_translation_y]]))))
        
        final_rotation = np.dot(final_rotation, rot)
        total_trans_x += closest_translation_x
        total_trans_y += closest_translation_y
        total_rotation_degrees += np.degrees(closest_rot_angle)

        # Compute distance between points
        distance_between_points.append(np.mean(distances))

        iteration_array.append(iter_num)

        # Compute the rotation angle in radians.
        rotation_radians = np.arctan2(rot[1, 0], rot[0, 0])

        # Convert rotation angle to degrees.
        rotation_angle_degrees = np.degrees(rotation_radians)
        rotation_degrees.append(rotation_angle_degrees)

        # Calculate translation in millimeters.
        translation_x_mm.append(closest_translation_x)
        translation_y_mm.append(closest_translation_y)
        
        # check convergence
        if (abs(closest_rot_angle) < convergence_rotation_threshold) \
                and (abs(closest_translation_x) < convergence_translation_threshold) \
                and (abs(closest_translation_y) < convergence_translation_threshold):
            
            print('Converged!')

            if False:
                # Plotting outside the loop
                for i, points in enumerate(all_points):
                    plt.plot(reference_points[:,0], reference_points[:,1], color="green")
                    plt.plot(points[:, 0], points[:, 1], color="blue")
                    plt.title(f'Iteration: {i + 1}')
                    plt.xlabel('X-axis')
                    plt.ylabel('Y-axis')
                    plt.show(block=False)
                    plt.pause(1)
                    # Clear the current figure to remove the previous points
                    plt.clf()
                plt.show()
            if verbose:
                print('Converged!')
            
            # Stop the ICP process
            break
    
    return total_rotation_degrees

def get_narco_lumen():

    narco_path='NARCO_Data/NARCO_rest_119/diastolic_contours.csv'

    ls1 = [[]]
    file = open(narco_path, "r")
    reader = csv.reader(file, delimiter='\t')

    for i, line in enumerate(reader):
        t = (float(line[1]), float(line[2]), float(line[3]))
        if float(line[3]) == 0.0:
            ls1[0].append(t)
        elif float(line[3]) > ls1[-1][-1][2]:
            ls1.append([t])
        else:
            ls1[-1].append(t)
    
    return ls1

def get_registration_point(file_path_oct_registration_point):

    if os.path.exists(file_path_oct_registration_point):
        # Read information from the file
        with open(file_path_oct_registration_point, 'r') as file:
            lines = file.readlines()
            for line in lines:
                key, value = map(str.strip, line.split(':'))
            registration_point = ast.literal_eval(value)
    
    return registration_point

def frames_alignment(contours, rotation_matrix, z_offset, height, width, conversion_factor):
    rotated_contours = []

    # Calculate the center of rotation
    center_y = (width / 2) * conversion_factor
    center_x = (height / 2) * conversion_factor

    # Case for rotation point, would not work with other code, due to for condition
    if len(contours) == 3: # for registration point
            current_contour = np.array(contours)
            idx = len(rotation_matrix)-1
            rot_angle = rotation_matrix[idx]  # Convert the list to a numpy array
            
            if current_contour is not None:
                # Translate to the center of rotation
                current_contour[0] -= center_x
                current_contour[1] -= center_y

                c, s = math.cos(np.radians(rot_angle)), math.sin(np.radians(rot_angle))

                # 2D rotation matrix for x-y plane
                rot_xy = np.array([[c, -s],
                                [s, c]])
                
                # Apply rotation only to x-y coordinates
                current_contour_xy_rotated = np.dot(current_contour[0:2], rot_xy.T)
                
                # Translate back to the original position
                current_contour_xy_rotated[0] += center_x
                current_contour_xy_rotated[1] += center_y
    
                # Combine rotated x-y coordinates with original z-values
                current_contour_rotated = [current_contour_xy_rotated[0], current_contour_xy_rotated[1], current_contour[2]]

                
                rotated_contours.append(current_contour_rotated)
    
    else:
        for idx, current_contour in enumerate(contours): # for stents
            current_contour = np.array(current_contour)
            print(idx)
            if len(current_contour) == 3:
                idx = int(current_contour[2]/z_offset)

                rot_angle = rotation_matrix[idx]  # Convert the list to a numpy array
                if current_contour is not None:

                    # Translate to the center of rotation
                    current_contour[0] -= center_x
                    current_contour[1] -= center_y

                    c, s = math.cos(np.radians(rot_angle)), math.sin(np.radians(rot_angle))
                    
                    # 2D rotation matrix for x-y plane
                    rot_xy = np.array([[c, -s],
                                    [s, c]])
                    
                
                # Apply rotation only to x-y coordinates
                current_contour_xy_rotated = np.dot(current_contour[0:2], rot_xy.T)
                
                # Translate back to the original position
                current_contour_xy_rotated[0] += center_x
                current_contour_xy_rotated[1] += center_y

                # Combine rotated x-y coordinates with original z-values
                current_contour_rotated = [current_contour_xy_rotated[0], current_contour_xy_rotated[1], current_contour[2]]
                    
                rotated_contours.append(current_contour_rotated)
            
            else: # for normal contours
                # idx = int(current_contour[0][2]/z_offset)
                rot_angle = rotation_matrix[idx]  # Convert the list to a numpy array
                if current_contour is not None:

                        # Translate to the center of rotation
                    current_contour[:, 0] -= center_x
                    current_contour[:, 1] -= center_y

                    c, s = math.cos(np.radians(rot_angle)), math.sin(np.radians(rot_angle))
                
                    # 2D rotation matrix for x-y plane
                    rot_xy = np.array([[c, -s],
                                    [s, c]])
                    
                    # Apply rotation only to x-y coordinates
                    current_contour_xy_rotated = np.dot(current_contour[:, :2], rot_xy.T)
                    
                    # Translate back to the original position
                    current_contour_xy_rotated[:, 0] += center_x
                    current_contour_xy_rotated[:, 1] += center_y

                    # Combine rotated x-y coordinates with original z-values
                    current_contour_rotated = np.column_stack((current_contour_xy_rotated, current_contour[:, 2]))
                    
                    rotated_contours.append(current_contour_rotated)
    
    return np.array(rotated_contours)

image_width = 512
image_height = 512

conversion_factor = 0.017557   # mm/pixel

narco_number = 119

registration_point_OCT = get_registration_point('NARCO_Data/NARCO_rest_119/NARCO119_registration_point_oct.txt')
oct_lumen_contours = get_narco_lumen()
oct_rotation_angles = np.zeros(len(oct_lumen_contours))
# oct_rotation_angles = get_rotation_matrix_ICP(oct_lumen_contours, z_distance=0.2) 
oct_lumen_point_cloud = frames_alignment(oct_lumen_contours, oct_rotation_angles, 0.0, image_height, image_width, conversion_factor)
registration_point_OCT = frames_alignment(registration_point_OCT, oct_rotation_angles, 0.0, image_height, image_width, conversion_factor)
center_line_registrator = center_line_registration()
grouped_OCT_lumen = center_line_registrator.restructure_point_clouds(oct_lumen_point_cloud, 0, len(oct_lumen_contours), z_distance=0, oct= False)

input_file_centerline = 'NARCO_Data/NARCO_rest_119/NARCO119_centerline.txt'
input_file_ct_registration_point = 'NARCO_Data/NARCO_rest_119/NARCO119_CT_registration.txt'
center_line_output_path = 'NARCO_Data/NARCO_rest_119/output/NARCO119_resampled_centerline.txt'
center_line_registration_points_output_path = 'NARCO_Data/NARCO_rest_119/output/NARCO119_centerline_registration_points.txt'
input_file_ct_mesh = 'NARCO_Data/NARCO_rest_119/NARCO119_CT.ply'
path_fused_point_cloud = 'NARCO_Data/NARCO_rest_119/output/NARCO' + str(narco_number) + '_fused_point_cloud.xyz'
path_point_cloud_oct = 'NARCO_Data/NARCO_rest_119/output/NARCO' + str(narco_number) + '_point_cloud_oct.xyz'
path_point_cloud_ct = 'NARCO_Data/NARCO_rest_119/output/NARCO' + str(narco_number) + '_point_cloud_ct.xyz'

# Load marked registration point in CT
registration_point_CT = center_line_registrator.parse_registration_point_CT(input_file_ct_registration_point)

if True:
    # Make smoother bifurication curves of centerline
    pc_smoother = PointCloudSmoothingVisualizer(input_file_centerline, registration_point_CT)
    smoothed_pc_centerline = pc_smoother.pc_centerline

    # Resample center line
    resampled_pc_centerline = center_line_registrator.resample_center_line(smoothed_pc_centerline, display_results=False, z_distance=0.2)

    # Save centerline
    with open(center_line_output_path, "w") as file:
        for point in resampled_pc_centerline:
            file.write(f"{point[0]} {point[1]} {point[2]}\n")

    # Compute center line vectors, that point from the previous centerline-point to the next centerline-point
    centerline_vectors = center_line_registrator.find_centerline_vectors(resampled_pc_centerline, False)

    # Get registration points and compute roation matrix
    centerline_registration_point_selector = PointCloudRegistrationPointSelectionVisualizer(resampled_pc_centerline, registration_point_CT)
    centerline_registration_start = centerline_registration_point_selector.selected_point_index_red
    selected_registration_point_CT = np.array(centerline_registration_point_selector.selected_registration_point_CT)
    centerline_registration_start_side_branch = centerline_registration_point_selector.selected_point_index_blue

    # Save registration points
    with open(center_line_registration_points_output_path, "w") as file:
        file.write(f"Registration_main_branch_start_idx: {centerline_registration_start}\n")
        file.write(f"Registration_side_branch_start_idx: {centerline_registration_start_side_branch}\n")    

oct_lumen_rotation_matrix, rotated_registration_point_OCT = center_line_registrator.get_oct_lumen_rotation_matrix(centerline_registration_start_side_branch, 0, registration_point_CT, resampled_pc_centerline, centerline_registration_start, grouped_OCT_lumen, 
                                                                                                                          registration_point_OCT, selected_registration_point_CT, 0, z_distance=0, display_results=False, oct=False)
  

# rotate OCT_frames
rotated_grouped_OCT_lumen = center_line_registrator.rotate_frames(grouped_OCT_lumen, oct_lumen_rotation_matrix, display_results=False)


registered_oct_lumen = center_line_registrator.register_OCT_frames_onto_centerline(rotated_grouped_OCT_lumen, centerline_registration_start, centerline_vectors,
                                                                                    resampled_pc_centerline, OCT_registration_frame=0, OCT_start_frame=0, z_distance=0.2, rotated_registration_point_OCT=rotated_registration_point_OCT, save_file=False, display_results=False)

# Load the .PLY file
mesh = o3d.io.read_triangle_mesh(input_file_ct_mesh)

# Decimate the mesh (optional)
mesh = mesh.simplify_quadric_decimation(target_number_of_triangles=100000)   #100000

# Create a regular point cloud from the mesh with a smaller voxel size
voxel_size = 0.05  # Adjust this value to control point density (smaller values = denser point cloud)
pcd = mesh.sample_points_uniformly(number_of_points=int(mesh.get_surface_area() / voxel_size))

# Extract the points as a numpy array
ct_points_ = pcd.points

ct_points = []
for point in ct_points_:
    ct_points.append([point[0], point[1], point[2]])
ct_points = np.array(ct_points)

# Visual point cloud editing:
point_cloud_visual_editior = point_cloud_visual_editing()
point_cloud_visual_editior.run_editor(ct_points, registered_oct_lumen)

point_cloud_save = point_cloud_visual_editior.fused_point_cloud
np.savetxt(path_fused_point_cloud, point_cloud_save, fmt='%f %f %f')
point_cloud_oct = point_cloud_visual_editior.point_cloud1
np.savetxt(path_point_cloud_oct, point_cloud_oct, fmt='%f %f %f')
point_cloud_ct = point_cloud_visual_editior.point_cloud2
np.savetxt(path_point_cloud_ct, point_cloud_ct, fmt='%f %f %f')

